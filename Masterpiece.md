No the lstm I'm using people to train the network I have a training set of data and biases. They do and my network does over a mosquitto broker network. None of the values are hidden. The mosquitto broker Topic path is my weight the data from my brocast of my current state of data at the path is my biases. I have public and private topics. Each One word lexemes is defined as a root path to subscribe to my public broadcast of data.  The next path after that is a publicKey that people can share with me private data. And subscripton past that is data and a request path to chain the different weights and biases of the pub sub because a response can be chained and all the definitions for the data to Request in the chain is defined on the root and since it's pub sub there is no saving huge data just opening and closing access to what root nodes are available.  That's why the nodes have to be able to dynamic select input size. Because broadcast channels open and close.  Also while the network  optionally shares weights and biases.  Each root subscription Open in each connection has a worker that is doing the actual mutation by training on data from all connections to a public channel  that is used for when either I or a peer connections is actively viewing a channels broadcast and us I ng the worker predictions in an auto complete as the selector for the best generation 

This way there can be a private context of my full root path topic as a weight mapped  to a data block store on my computer where I store the definition of the data to retrieve. Then I also have a in memory  mapping of my current activity of my subscriptions. Updating the epochs of the worker training every use of autocorrect by updating the weights with each peer sharing the same public path and the bias will be a yes if keep typing and a no if deleting.  Or if it's a byte data stream it's a mutation  on there stream 

So that was the protected  in memory context of the current list of active channels and the private neural also btaching all root nodes in the local blockstore network.  All the root paths which are one word lexemes weiths and also definitions on the local blockstore. 
And me or which ever peer personally advancing each epoch based on what they publish vs their local in memory work total blockstore. 

Then there is a active channel training of the public worker worker that trains on all active messages and also provides a prediction for the auto complete of connect peers neural network. 

Lastly there will be a last Context of training like your hidden hidden but "hidden hidden hidden hidden" As in trains on all the data and constantly broadcast its responses.

Each root path should have a have a definition of how ever any one wants to define it in plain text.  Any person opening a subscription opens can define on their root node a response to present.  The first subpath after their path is a publicKey for Auth.  After that is a rpc input for the person opening a subscription.   

Each root word is a one word lexeme with a custom definition.  There is a Auth signature  then a path for instance
/PeerId
/Wallet
/Marketplace
/Marketplace/Board/Listing/Service
/Marketplace/Board/Listing/Service/Qm4dyj74werf65

Someone can go to a marketplace Board listing service and open subscription on thier root Node at that location and get publishings from peers of Request messages whatever hopefully a auth function that publishers signature on all post which 
Is how someone can request a private context. Also when the 

Will this neural network structure work